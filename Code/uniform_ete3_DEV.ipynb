{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Bio import Phylo\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 things to simulate that would be great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = ete3.Tree() # Creates an empty tree\n",
    "A = my_tree.add_child(name=\"A\", dist=1.0) \n",
    "B = A.add_sister(name=\"B\", dist=1.0) \n",
    "C = my_tree.add_child(name=\"C\", dist=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree.render('%%inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    all_leaves = my_tree.get_leaves()\n",
    "    choice = random.choice(all_leaves)\n",
    "    choice.add_child(name=\"A\", dist=1.0)\n",
    "    choice.add_child(name=\"B\", dist=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree.get_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pectinate(n=2):\n",
    "    tree = ete3.Tree() # Creates an empty tree\n",
    "    A = tree.add_child(name=\"\", dist=1.) # Adds a new child to the current tree root\n",
    "    B = tree.add_child(name=\"\", dist=1.)\n",
    "    top_node = A\n",
    "    for i in range(n-2):\n",
    "        temp_a = top_node.add_child(name=\"\", dist=1.)\n",
    "        temp_b = top_node.add_child(name=\"\", dist=1.)\n",
    "        top_node = temp_a\n",
    "    return tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = create_pectinate(32)\n",
    "tree.render('%%inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "letters = string.ascii_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ete3.Tree() # Creates an empty tree\n",
    "A = tree.add_child(name='a', dist=1.) # Adds a new child to the current tree root\n",
    "B = tree.add_child(name='', dist=1.)\n",
    "top_node = B\n",
    "for i in range(16-2):\n",
    "#     temp_a = top_node.add_child(dist=1.)\n",
    "#     temp_b = top_node.add_child(dist=1.)\n",
    "    temp_a = top_node.add_child(name=letters[i+1], dist=1.)\n",
    "    temp_b = top_node.add_child(name=letters[i+2], dist=1.)\n",
    "    top_node = temp_b\n",
    "print(len(tree.get_leaves()))\n",
    "#ancestor.add_features(nodetype=\"internal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.render('%%inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in tree.traverse():\n",
    "    if len(node.get_children()) == 2:\n",
    "        node.name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All sweep\n",
    "\n",
    "This algorithm uses (will use) recursive concatenation of small trees to build up a set of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "size = 1000\n",
    "split_dict = {}\n",
    "split_dict[1] = []\n",
    "l_array = np.array([i for i in range(1, (size//2)+1)])\n",
    "r_array = np.zeros((size//2))\n",
    "for smaller in range(2, size+1, 1):\n",
    "    r_array[:smaller-1] += 1\n",
    "    split_dict[smaller] = (l_array[:smaller//2], r_array[:smaller//2])\n",
    "#     split_dict[smaller] = list(zip(l_array[:smaller//2], r_array[:smaller//2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform sampler using the \"Dendrogram capacity\" method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First get dictionary of the number of possible trees for all values up to and including *n***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=8\n",
    "n_trees_dict = {}\n",
    "n_trees_dict[1] = 1\n",
    "\n",
    "split_trees_dict = {}\n",
    "probability_dict = {}\n",
    "for tree in range(2, n+1):\n",
    "    range_val = tree//2+1\n",
    "    tots = []\n",
    "    split_pairs = []\n",
    "    for i in range(1, range_val):\n",
    "        j = tree-i\n",
    "        split_pairs.append((j,i))\n",
    "        if i != j:\n",
    "            tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "        else:\n",
    "            tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "    total_possible = sum(tots)\n",
    "    probability_dict[tree] = [i/total_possible for i in tots]\n",
    "    n_trees_dict[tree] = total_possible\n",
    "    split_trees_dict[tree] = split_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_dict[4], split_trees_dict[4], probability_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_dict[8], split_trees_dict[8], probability_dict[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=4\n",
    "(((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_trees_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even_probability_dict = {}\n",
    "# for i in range(2, 20//2+1):\n",
    "#     options = split_trees_dict[i]\n",
    "#     print(i, options)\n",
    "#     prob_modifier = list(range(i-2, 0, -1))\n",
    "#     print(prob_modifier)\n",
    "even_probability_dict_l = {}\n",
    "even_probability_dict_r = {}\n",
    "\n",
    "for tree in range(2, n+1):\n",
    "    print('######', tree)\n",
    "    range_val = tree//2+1\n",
    "    tots = []\n",
    "    split_pairs = []\n",
    "    for i in range(1, range_val):\n",
    "        j = tree-i\n",
    "#         if i != j:\n",
    "#             continue\n",
    "        print(j,i)\n",
    "        split_pairs.append((j,i))\n",
    "        if i != j:\n",
    "            tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "        else:\n",
    "            tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "    print(split_pairs)\n",
    "    tots_l = tots*np.arange(len(split_pairs), 0, -1)\n",
    "    tots_r = tots*np.arange(1, len(split_pairs)+1, 1)\n",
    "    tots_l = list(tots_l)\n",
    "    tots_r = list(tots_r)\n",
    "    total_possible_l = sum(tots_l)\n",
    "    total_possible_r = sum(tots_r)\n",
    "    even_probability_dict_l[tree] = [i/total_possible_l for i in tots_l]\n",
    "    even_probability_dict_r[tree] = [i/total_possible_r for i in tots_r]\n",
    "\n",
    "#     split_trees_dict[tree] = split_pairs\n",
    "    \n",
    "    \n",
    "#     l_side = []\n",
    "#     all_to_all = split_trees_dict[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_probability_dict_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_probability_dict_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8+7+6+5+4+3+2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_recursive(n, path, split_trees_dict, probability_dict, repeat_possibility=False):\n",
    "#     if even_split == True:\n",
    "        \n",
    "#     else:\n",
    "        \n",
    "    index = np.random.choice(len(split_trees_dict[n]), p=probability_dict[n])\n",
    "    choice = split_trees_dict[n][index]\n",
    "#     print(choice)\n",
    "    path.append(choice)\n",
    "\n",
    "    l_split = choice[0]\n",
    "    r_split = choice[1]\n",
    "    if l_split != 1:\n",
    "        if l_split == 2:\n",
    "            path.append((1,1))\n",
    "        else:\n",
    "            path = select_recursive(l_split, path, split_trees_dict, probability_dict, repeat_possibility)\n",
    "\n",
    "    ######################\n",
    "    if l_split == r_split:\n",
    "        ###DangerZone\n",
    "        repeat_possibility = True\n",
    "    ######################\n",
    "    if r_split != 1:\n",
    "        if r_split == 2:\n",
    "            path.append((1,1))\n",
    "        else:\n",
    "            path = select_recursive(r_split, path, split_trees_dict, probability_dict, repeat_possibility)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tuple(select_recursive(n, [], split_trees_dict, probability_dict))\n",
    "assert len(tmp) == n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = []\n",
    "for i in range(200):\n",
    "    tmp = tuple(select_recursive(n, [], split_trees_dict, probability_dict))\n",
    "    assert len(tmp) == n-1\n",
    "    listy.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = Counter(listy)\n",
    "# assert len(counter_dict.keys()) == n_trees_dict[n]\n",
    "print(counter_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counter_dict.keys()), n_trees_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in counter_dict.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = counter_dict.keys()\n",
    "for key in sorted(keys):\n",
    "    print(key, counter_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_dict[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay forget everything above here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_trees_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nonrecursive(10, split_trees_dict, probability_dict, l_probability_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=12\n",
    "listy = []\n",
    "for i in range(1000):\n",
    "    tmp = tuple(sample_nonrecursive(n, split_trees_dict, probability_dict, l_probability_dict))\n",
    "#     assert len(tmp) == n-1\n",
    "    listy.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupley = []\n",
    "for i in listy:\n",
    "    toft = tuple(tuple(x) for x in i)\n",
    "    tupley.append(toft)\n",
    "counter_dict = Counter(tupley)\n",
    "print(len(counter_dict.keys()), n_trees_dict[n])\n",
    "print(stats.chisquare(list(counter_dict.values())))\n",
    "# counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = 6\n",
    "n_trees_dict[blah], (((blah**2)-blah)/2)+blah, split_trees_dict[blah]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_probability_dict[6], probability_dict[6], split_trees_dict[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_probability_dict[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tree(n, split_trees_dict, probability_dict, l_probability_dict):\n",
    "    ###Get the first split here\n",
    "    init_index = np.random.choice(len(split_trees_dict[n]), p=probability_dict[n])\n",
    "    init_choice = split_trees_dict[n][init_index]\n",
    "    starting_list = [init_choice]\n",
    "    if init_choice[0] == init_choice[1]:\n",
    "        splits = select_recursive_left(init_choice, starting_list, split_trees_dict,\\\n",
    "                                  probability_dict, l_probability_dict, symmetry=True)\n",
    "        splits = select_recursive_right(init_choice, starting_list, split_trees_dict,\\\n",
    "                                  probability_dict, l_probability_dict, symmetry=True)\n",
    "    else:\n",
    "        splits = select_recursive(init_choice[0], starting_list, split_trees_dict,\\\n",
    "                                  probability_dict, l_probability_dict)\n",
    "        splits = select_recursive(init_choice[0], starting_list, split_trees_dict,\\\n",
    "                                  probability_dict, l_probability_dict)\n",
    "    return splits\n",
    "\n",
    "\n",
    "def select_recursive_rside(splits, path, split_trees_dict, probability_dict,\\\n",
    "                               l_probability_dict, l_index_choice):\n",
    "    path.append(splits)\n",
    "    if splits == (1,1):\n",
    "        pass\n",
    "    else:\n",
    "        ###This introduces an asymmetry in choices between my two sides(!)\n",
    "        l_split = splits[0]\n",
    "        r_split = splits[1]\n",
    "        l_index = np.random.choice(len(split_trees_dict[l_split]), p=l_probability_dict[l_split])\n",
    "        l_choice = split_trees_dict[l_split][l_index]\n",
    "\n",
    "        ###R split is now conditional on the choice of l-split! Perhaps this monstrosity should be re-computed\n",
    "        ###but doing it separately here for now.\n",
    "        if r_split == 1:\n",
    "            r_choice = None\n",
    "        else:\n",
    "            naive = probability_dict[r_split]\n",
    "            naive = naive*\\\n",
    "                np.concatenate((np.ones(l_index+1, dtype=object),\\\n",
    "                                np.zeros(len(naive)-(l_index+1), dtype=object)), axis=0)\n",
    "            naive = list(naive)\n",
    "            totals = sum(naive)\n",
    "            adj_probs = [i/totals for i in naive]\n",
    "            r_index = np.random.choice(len(split_trees_dict[r_split]), p=adj_probs)\n",
    "            r_choice = split_trees_dict[r_split][r_index]\n",
    "        if l_choice != r_choice:\n",
    "            path = select_recursive(l_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "            if r_choice:\n",
    "                path = select_recursive(r_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "        else:\n",
    "            path = select_recursive_lside(l_choice, path, split_trees_dict,\\\n",
    "                                              probability_dict, l_probability_dict)\n",
    "            if r_choice:\n",
    "                path = select_recursive_rside(r_choice, path, split_trees_dict,\\\n",
    "                                                  probability_dict, l_probability_dict) \n",
    "        \n",
    "    return path\n",
    "\n",
    "def select_recursive_lside(n, path, split_trees_dict, probability_dict,\\\n",
    "                               l_probability_dict, symmetry=False):\n",
    "    \n",
    "    index = np.random.choice(len(split_trees_dict[n]), p=l_probability_dict[n])\n",
    "    split = split_trees_dict[n][index]\n",
    "    path.append(split)\n",
    "  \n",
    "    elif (split[0] == split[1]):\n",
    "        path, l_lineage = select_recursive_lside(split[0], path, split_trees_dict, probability_dict, l_probability_dict) \n",
    "        path = select_recursive_rside(split[1], path, split_trees_dict, probability_dict, l_probability_dict) \n",
    "\n",
    "    \n",
    "    \n",
    "    if split == (1,1):\n",
    "        pass\n",
    "    else:\n",
    "        ###This introduces an asymmetry in choices between my two sides(!)\n",
    "        l_split = splits[0]\n",
    "        r_split = splits[1]\n",
    "\n",
    "\n",
    "        ###R split is now conditional on the choice of l-split! Perhaps this monstrosity should be re-computed\n",
    "        ###but doing it separately here for now.\n",
    "        if r_split == 1:\n",
    "            r_choice = None\n",
    "        else:\n",
    "            naive = probability_dict[r_split]\n",
    "            naive = naive*\\\n",
    "                np.concatenate((np.ones(l_index+1, dtype=object),\\\n",
    "                                np.zeros(len(naive)-(l_index+1), dtype=object)), axis=0)\n",
    "            naive = list(naive)\n",
    "            totals = sum(naive)\n",
    "            adj_probs = [i/totals for i in naive]\n",
    "            r_index = np.random.choice(len(split_trees_dict[r_split]), p=adj_probs)\n",
    "            r_choice = split_trees_dict[r_split][r_index]\n",
    "        if l_choice != r_choice:\n",
    "            path = select_recursive(l_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "            if r_choice:\n",
    "                path = select_recursive(r_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "        else:\n",
    "            path = select_recursive_lside(l_choice, path, split_trees_dict,\\\n",
    "                                              probability_dict, l_probability_dict)\n",
    "            probs = \n",
    "            if r_choice:\n",
    "                path = select_recursive_rside(r_choice, path, split_trees_dict,\\\n",
    "                                                  probability_dict, l_probability_dict) \n",
    "        \n",
    "    return path\n",
    "\n",
    "def get_symmetric_lineages(l_side, r_side):\n",
    "    l_lineage = []\n",
    "    r_lineage = []\n",
    "    while l_lineage == r_lineage:\n",
    "        index = np.random.choice(len(split_trees_dict[l_val]), p=l_probability_dict[l_val])\n",
    "        l_split = split_trees_dict[l_side][index]\n",
    "        l_lineage.append(l_split)\n",
    "        \n",
    "        naive = probability_dict[r_side]\n",
    "        naive = naive*\\\n",
    "            np.concatenate((np.ones(index+1, dtype=object),\\\n",
    "                            np.zeros(len(naive)-(index+1), dtype=object)), axis=0)\n",
    "        naive = list(naive)\n",
    "        totals = sum(naive)\n",
    "        adj_probs = [i/totals for i in naive]\n",
    "        r_index = np.random.choice(len(split_trees_dict[r_side]), p=adj_probs)\n",
    "        r_split = split_trees_dict[r_side][r_index]\n",
    "        r_lineage.append(r_split)\n",
    "        \n",
    "        l_side = l_split[0]\n",
    "        r_side = r_split[0]\n",
    "    return l_lineage, r_lineage\n",
    "\n",
    "\n",
    "def select_recursive(n, path, split_trees_dict, probability_dict, l_probability_dict, symmetry=False):\n",
    "    \"\"\"\n",
    "    Oooof this started out so clean and nice. Needs a re-do\n",
    "    \"\"\"\n",
    "    index = np.random.choice(len(split_trees_dict[n]), p=probability_dict[n])\n",
    "    split = split_trees_dict[n][index]\n",
    "    path.append(split)\n",
    "\n",
    "    if split == (1, 1):\n",
    "        pass\n",
    "    \n",
    "    elif (split[0] != split[1]):\n",
    "        for choice in split:\n",
    "            if side != 1:\n",
    "                path = select_recursive(choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "                \n",
    "    elif (splits[0] == splits[1]):\n",
    "        ###Dive in until they differ\n",
    "        l_lineage, r_lineage = get_symmetric_lineages()\n",
    "        \n",
    "        \n",
    "        path, l_lineage = select_recursive_lside(split[0], path, split_trees_dict, probability_dict, l_probability_dict) \n",
    "        path = select_recursive_rside(split[1], path, split_trees_dict, probability_dict, l_probability_dict) \n",
    "\n",
    "    return path\n",
    "\n",
    "# def select_recursive(splits, path, split_trees_dict, probability_dict, l_probability_dict):\n",
    "#     \"\"\"\n",
    "#     Oooof this started out so clean and nice. Needs a re-do\n",
    "#     \"\"\"\n",
    "#     path.append(splits)\n",
    "#     if splits == (1, 1):\n",
    "#         pass\n",
    "    \n",
    "#     elif (splits[0] != splits[1]) or (splits[0] in [2,3]):\n",
    "#         for split in splits:\n",
    "#             if split != 1:\n",
    "#                 index = np.random.choice(len(split_trees_dict[split]), p=probability_dict[split])\n",
    "#                 choice = split_trees_dict[split][index]\n",
    "#                 path = select_recursive(choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "#     else:\n",
    "#         ###This whole thing is equivalent to sampling from the upper triangle (including identity) of a matrix\n",
    "#         split = splits[0]\n",
    "#         l_index = np.random.choice(len(split_trees_dict[split]), p=l_probability_dict[split])\n",
    "#         l_choice = split_trees_dict[split][l_index]\n",
    "#         path = select_recursive(l_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "        \n",
    "#         ###R split is conditional on the choice of l-split! Perhaps this monstrosity should be re-computed\n",
    "#         ###but doing it separately here for now.\n",
    "#         naive = probability_dict[split]\n",
    "#         naive = naive*\\\n",
    "#             np.concatenate((np.ones(l_index+1, dtype=object),\\\n",
    "#                             np.zeros(len(naive)-(l_index+1), dtype=object)), axis=0)\n",
    "#         naive = list(naive)\n",
    "#         totals = sum(naive)\n",
    "#         adj_probs = [i/totals for i in naive]\n",
    "#         r_index = np.random.choice(len(split_trees_dict[split]), p=adj_probs)\n",
    "#         r_choice = split_trees_dict[split][r_index]\n",
    "#         if r_choice == l_choice:\n",
    "#             pass\n",
    "#         path = select_recursive(r_choice, path, split_trees_dict, probability_dict, l_probability_dict)\n",
    "        \n",
    "#     return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_probability_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = probability_dict[5]\n",
    "l_index = 0\n",
    "naive = naive*\\\n",
    "            np.concatenate((np.ones(l_index+1, dtype=object),\\\n",
    "                            np.zeros(len(naive)-(l_index+1), dtype=object)), axis=0)\n",
    "naive = list(naive)\n",
    "totals = sum(naive)\n",
    "adj_probs = [i/totals for i in naive]\n",
    "r_index = np.random.choice(len(split_trees_dict[5]), p=adj_probs)\n",
    "r_choice = split_trees_dict[5][r_index]\n",
    "naive, totals, adj_probs, r_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build up the necessary dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "n_trees_dict = {}\n",
    "n_trees_dict[1] = 1\n",
    "\n",
    "split_trees_dict = {}\n",
    "probability_dict = {}\n",
    "for tree in range(2, n+1):\n",
    "    range_val = tree//2+1\n",
    "    tots = []\n",
    "    split_pairs = []\n",
    "    for i in range(1, range_val):\n",
    "        j = tree-i\n",
    "        split_pairs.append((j,i))\n",
    "        if i != j:\n",
    "            tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "        else:\n",
    "            tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "    total_possible = sum(tots)\n",
    "    probability_dict[tree] = [i/total_possible for i in tots]\n",
    "    n_trees_dict[tree] = total_possible\n",
    "    split_trees_dict[tree] = split_pairs\n",
    "    \n",
    "####I might be able to accomplish the same thing by just multiplying these by the probabilities above...hmm\n",
    "l_probability_dict = {}\n",
    "for tree in range(2, n+1):\n",
    "    range_val = tree//2+1\n",
    "    tots = []\n",
    "    split_pairs = []\n",
    "    for i in range(1, range_val):\n",
    "        j = tree-i\n",
    "        split_pairs.append((j,i))\n",
    "        if i != j:\n",
    "            tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "        else:\n",
    "            tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "#     tots_l = tots*np.arange(len(split_pairs), 0, -1, dtype=object)\n",
    "\n",
    "    tots_l = tots*np.arange(1, len(split_pairs)+1, 1, dtype=object)\n",
    "    tots_l = list(tots_l)\n",
    "#     print(tots_l)\n",
    "    total_possible_l = sum(tots_l)\n",
    "    l_probability_dict[tree] = [i/total_possible_l for i in tots_l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the sampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listy = []\n",
    "for i in range(10000):\n",
    "    tmp = tuple(sample_tree(n, split_trees_dict, probability_dict, l_probability_dict))\n",
    "#     print(tmp)\n",
    "    assert len(tmp) == n-1\n",
    "    listy.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = Counter(listy)\n",
    "# counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chisquare(list(counter_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counter_dict.keys()), n_trees_dict[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in counter_dict.items():\n",
    "#     if key[0]==(5,5):\n",
    "    if key[0]==(5,5) and key[1]==(4,1):\n",
    "#     if key[0]==(6,6) and key[1]==(5,1):\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees_dict[6], n_trees_dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.zeros(1, dtype=object), np.ones(2-1, dtype=object)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begrudgingly using the array tables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table_sparse(n):\n",
    "    n_trees_dict = {}\n",
    "    n_trees_dict[1] = 1\n",
    "    tree_list = [1]\n",
    "    lside = [1]\n",
    "    rside = [None]\n",
    "    for tree in range(2, n+1):\n",
    "        range_val = tree//2+1\n",
    "        tots = []\n",
    "        split_pairs = []\n",
    "        for i in range(1, range_val):\n",
    "            j = tree-i\n",
    "            split_pairs.append((j,i))\n",
    "            tree_list.append(tree)\n",
    "            lside.append(j)\n",
    "            rside.append(i)\n",
    "            if i != j:\n",
    "                tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "            else:\n",
    "                tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "        total_possible = sum(tots)\n",
    "        n_trees_dict[tree] = total_possible\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(tree_list, lside, rside)), dtype=object)\n",
    "\n",
    "    return df, n_trees_dict\n",
    "\n",
    "def build_table_full(n):\n",
    "    df = pd.DataFrame([[1, 1, 1, 1, 1, 1, 1]], index=[0], dtype=object)\n",
    "    counter = 1\n",
    "\n",
    "    n_trees_dict = {}\n",
    "    n_trees_dict[1] = 1\n",
    "\n",
    "    \n",
    "    for tree in range(2, n+1):\n",
    "        range_val = tree//2+1\n",
    "        tots = []\n",
    "        split_pairs = []\n",
    "        for i in range(1, range_val):\n",
    "            j = tree-i\n",
    "            split_pairs.append((j,i))\n",
    "            \n",
    "        for j,i in split_pairs:\n",
    "            df.at[counter, 0] = tree\n",
    "            df.at[counter, 1] = j\n",
    "            df.at[counter, 2] = i\n",
    "            if i != j:\n",
    "                df.at[counter, 5] = n_trees_dict[i]*n_trees_dict[j]\n",
    "                tots.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "            else:\n",
    "                df.at[counter, 5] = (((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i]\n",
    "                tots.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "            df.at[counter, 3] = n_trees_dict[j]\n",
    "            df.at[counter, 4] = n_trees_dict[i]\n",
    "            df.at[counter, 6]= df[df[0]==tree][5].sum()\n",
    "            counter += 1\n",
    "\n",
    "        total_possible = df[df[0]==tree][5].sum()\n",
    "#         total_possible = sum(tots)\n",
    "        n_trees_dict[tree] = total_possible\n",
    "            \n",
    "    return df, n_trees_dict\n",
    "\n",
    "# def build_tree_full(df, n_trees_dict, n_leaves):\n",
    "#     '''\n",
    "#     Maybe this is where my recursive algorithm could/should lie?\n",
    "#     '''\n",
    "#     #Start by first looking at the end of the df\n",
    "#     n_trees = n_trees_dict[n]\n",
    "#     #Establishing which_tree I want to grab\n",
    "#     tree_index = random.randint(1, n_trees)\n",
    "        \n",
    "#     possible_set = df[df[0]==n_leaves]\n",
    "#     line, n_within = select_line(possible_set, tree_index)\n",
    "\n",
    "#     l_n, r_n = select_descendants(n_within, df[df[0]==line[1]].iloc[-1][6], df[df[0]==line[2]].iloc[-1][6])\n",
    "#     #Now need line and index of these children\n",
    "#     l_child_set = df[df[0]==line[1]]\n",
    "#     l_line, l_n_within = select_line(l_child_set, l_n)\n",
    "#     r_child_set = df[df[0]==line[2]]\n",
    "#     r_line, r_n_within = select_line(r_child_set, r_n)\n",
    "\n",
    "#     my_tree = ete3.Tree()\n",
    "#     l_split = my_tree.add_child(name=(l_line.name, l_n_within)) \n",
    "#     r_split = my_tree.add_child(name=(r_line.name, r_n_within)) \n",
    "#     my_tree = build_recursive_full(my_tree, my_tree, df)\n",
    "#     return my_tree\n",
    "\n",
    "# def build_recursive_full(my_tree, node, df):\n",
    "#     if node.children == []:\n",
    "#         return my_tree\n",
    "#     for child_node in node.children:\n",
    "#         if child_node.name[0] != 0:\n",
    "#             child_name, child_n = child_node.name\n",
    "#             line = df.loc[child_name]\n",
    "#             ###How many options were there\n",
    "#             level = df[df[0]==line[0]]\n",
    "#             l_n, r_n = select_descendants(child_n,\\\n",
    "#                                      df[df[0]==line[1]].iloc[-1][6], df[df[0]==line[2]].iloc[-1][6])\n",
    "#             #Now need line and index of these children\n",
    "#             l_child_set = df[df[0]==line[1]]\n",
    "#             l_line, l_n_within = select_line(l_child_set, l_n)\n",
    "#             r_child_set = df[df[0]==line[2]]\n",
    "#             r_line, r_n_within = select_line(r_child_set, r_n)\n",
    "            \n",
    "#             l_split = child_node.add_child(name=(l_line.name, l_n_within)) \n",
    "#             r_split = child_node.add_child(name=(r_line.name, r_n_within))     \n",
    "#             my_tree = build_recursive_full(my_tree, child_node, df)\n",
    "\n",
    "#     return my_tree\n",
    "\n",
    "# def select_line(df, index):\n",
    "#     try:\n",
    "#         line_before = df[df[6]<index].iloc[-1]\n",
    "#         return df.loc[line_before.name+1], index-line_before[6]\n",
    "#     except IndexError:\n",
    "#         line = df.iloc[0]\n",
    "#         return line, index\n",
    "    \n",
    "# def select_descendants(i, l_trees, r_trees):\n",
    "#     \"\"\"\n",
    "#     Technically not just selecting the square with this update...\n",
    "#     \"\"\"\n",
    "#     if l_trees != r_trees:\n",
    "#         lside = (i-1)%l_trees+1\n",
    "#         rside = ((i-1)//l_trees)+1\n",
    "#     else:\n",
    "#         lside, rside = tri_indices(i-1, l_trees)\n",
    "#         lside += 1\n",
    "#         rside += 1\n",
    "#     return lside, rside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####This might actually work!\n",
    "def tri_indices(i, mat_len):\n",
    "    ii = (mat_len*(mat_len+1))//2-1-i\n",
    "#     K = floor((sqrt((8*ii)+1)-1)/2)\n",
    "    K = (isqrt(8*ii+1)-1)//2\n",
    "    row = mat_len-1-K\n",
    "    return row, i - (mat_len*(mat_len-1)//2) + ((mat_len-row)*((mat_len-row)-1))//2\n",
    "\n",
    "def isqrt(n):\n",
    "    \"\"\"\n",
    "    Need to upgrade to python 3.8 for math.isqrt()\n",
    "    \"\"\"\n",
    "    x = n\n",
    "    y = (x + 1) // 2\n",
    "    while y < x:\n",
    "        x = y\n",
    "        y = (x + n // x) // 2\n",
    "    return x\n",
    "\n",
    "\n",
    "###Testing my triangle indices\n",
    "# from numpy import triu_indices, sqrt\n",
    "# n = 200\n",
    "# for k in range((n**2-n)//2+n):\n",
    "#     i, j = mat_indices(k, n)\n",
    "#     assert np.triu_indices(n, k=0)[0][k] == i\n",
    "#     assert np.triu_indices(n, k=0)[1][k] == j, print('###',np.triu_indices(n, k=0)[1][k], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = build_table_full(10)\n",
    "# df, trash = build_table_sparse(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "df, n_trees_dict = build_table_full(n)\n",
    "testy = []\n",
    "for i in range(20):\n",
    "    tree = build_tree_full(df, n_trees_dict, n)\n",
    "    tree.name = ''\n",
    "    for node in tree.get_descendants():\n",
    "        node.name = ''\n",
    "    assert len(tree.get_leaves()) == n\n",
    "    testy.append(tree.write('newick', format=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phylo.draw(Phylo.read(StringIO(testy[0]), 'newick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = Counter(testy)\n",
    "print(len(counter_dict.values()))\n",
    "print(stats.chisquare(list(counter_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for newick in counter_dict.keys():\n",
    "    print(counter_dict[newick])\n",
    "    Phylo.draw(Phylo.read(StringIO(newick), 'newick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more reasonable run-time solution...perhaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####This might actually work!\n",
    "def triu_indices_AJH(i, mat_len):\n",
    "    \"\"\"\n",
    "    This function gets the triangular indices from a square matrix (including the diagonal). \n",
    "    It was developed with a bit of guess and check and using some functions/solutions I found \n",
    "    online but it looks robust. Should be tested more extensively but my test against numpy triu_indices()\n",
    "    works well (and this of course skips the matrix building step).\n",
    "    \n",
    "    Critical differences to some fxns found online were making sure it runs on integer math to handle\n",
    "    enormous numbers.\n",
    "    \n",
    "    Relies on isqrt, which should be the python implementation in >3.8 but Newton's method works (slowly)\n",
    "    \n",
    "    Inputs:\n",
    "        i - the linear index of interest\n",
    "        m - the dimensions of one side of the square matrix\n",
    "        \n",
    "    Outputs\n",
    "        row index\n",
    "        column index\n",
    "    \"\"\"\n",
    "    ii = (mat_len*(mat_len+1))//2-1-i\n",
    "    K = (isqrt(8*ii+1)-1)//2\n",
    "    row = mat_len-1-K\n",
    "    return row, i - (mat_len*(mat_len-1)//2) + ((mat_len-row)*((mat_len-row)-1))//2\n",
    "\n",
    "\n",
    "def triu_accuracy_test(max_n_to_test):\n",
    "    \"\"\"\n",
    "    Tests the accuracy of my triangle indices test compared to numpy.\n",
    "    The advantage of mine is not having to actually build the matrix and instead work directly \n",
    "    with the dimensions.\n",
    "    \n",
    "    Will run slowly so am arbitrarily limiting max_n_to_test to 200\n",
    "    \"\"\"\n",
    "    if max_n_to_test > 100:\n",
    "        max_n_to_test = 100\n",
    "        print(\"Setting max variable to test to 100, test takes a long time otherwise.\")\n",
    "    for n in range(1, max_n_to_test+1):\n",
    "        for k in range(((n**2-n)//2)+n):\n",
    "            i, j = triu_indices_AJH(k, n)\n",
    "            assert np.triu_indices(n, k=0)[0][k] == i\n",
    "            assert np.triu_indices(n, k=0)[1][k] == j, print('###',np.triu_indices(n, k=0)[1][k], j)\n",
    "\n",
    "def isqrt(n):\n",
    "    \"\"\"\n",
    "    Integer square root. Need to upgrade to python 3.8 for math.isqrt()\n",
    "    \"\"\"\n",
    "    x = n\n",
    "    y = (x + 1) // 2\n",
    "    while y < x:\n",
    "        x = y\n",
    "        y = (x + n // x) // 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dicts(n):\n",
    "    ###The dictionary that will hold the number of possible trees with a given number of leaves\n",
    "    n_trees_dict = {}\n",
    "    ###It has a few quirks that need to be added manually\n",
    "    n_trees_dict[np.nan] = np.nan\n",
    "    n_trees_dict[1] = 1\n",
    "    \n",
    "    ###Establishing the arrays that hold the number of downstream children on the left and right\n",
    "    ###sides of a bifurcation\n",
    "    l_side = [1]\n",
    "    r_side = [np.nan]\n",
    "    ###A pointer dictionary that tracks where in those arrays trees with a given number of leaves reside\n",
    "    pointer_dict = {}\n",
    "    pointer_dict[1] = (0, 0) #i.e. the first index contains trees related to 1 downstream leaf\n",
    "    \n",
    "    ###Build up the quantities\n",
    "    for tree in range(2, n+1):\n",
    "        starting_index = len(l_side)\n",
    "        range_val = tree//2+1\n",
    "        totals = []\n",
    "        for i in range(1, range_val):\n",
    "            j = tree-i\n",
    "            l_side.append(j)\n",
    "            r_side.append(i)\n",
    "            if i!=j:\n",
    "                totals.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "            else:\n",
    "                totals.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "        ending_index = len(l_side)-1\n",
    "        totals = sum(totals)\n",
    "        n_trees_dict[tree] = totals\n",
    "        pointer_dict[tree] = (starting_index, ending_index)\n",
    "    return l_side, r_side, n_trees_dict, pointer_dict \n",
    "\n",
    "\n",
    "def build_tree_full(lside_arr, rside_arr, n_trees_dict, pointer_dict, n_leaves):\n",
    "    '''\n",
    "    Maybe this is where my recursive algorithm could/should lie?\n",
    "    '''\n",
    "    #Start by first looking at the end of the df\n",
    "    n_trees = n_trees_dict[n]\n",
    "    #Establishing the index of the tree that I want to grab\n",
    "    tree_index = random.randint(0, n_trees-1)\n",
    "    #Getting the number of descendants and index within that set\n",
    "    l_children, r_children, n_within = select_index(pointer_dict,\\\n",
    "                                                    lside_arr, rside_arr, n_trees_dict, tree_index, n)\n",
    "\n",
    "    l_index, r_index = select_descendants(l_children, r_children, n_within, n_trees_dict)\n",
    "    \n",
    "    l_l_children, l_r_children, l_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, l_index, l_children)\n",
    "    \n",
    "    r_l_children, r_r_children, r_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, r_index, r_children)\n",
    "\n",
    "    my_tree = ete3.Tree()\n",
    "    l_split = my_tree.add_child(name=(l_l_children, l_r_children, l_n_within)) \n",
    "    r_split = my_tree.add_child(name=(r_l_children, r_r_children, r_n_within)) \n",
    "    my_tree = build_recursive_full(my_tree, my_tree, lside_arr, rside_arr, n_trees_dict, pointer_dict)\n",
    "    return my_tree\n",
    "\n",
    "def select_index(pointer_dict, lside_arr, rside_arr, n_trees_dict, tree_index, n):\n",
    "    \"\"\"\n",
    "    The real problem is that I'm generating these values at each call\n",
    "    but like if I don't, I'll have to store them and for large n (>100)\n",
    "    this gets positively enormous/prohibitive.\n",
    "    \n",
    "    So instead, I generate this on the fly each time around? \n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return np.nan, np.nan, 0\n",
    "    lside_temp = np.array(lside_arr[pointer_dict[n][0]:pointer_dict[n][1]+1], dtype=object)\n",
    "    rside_temp = np.array(rside_arr[pointer_dict[n][0]:pointer_dict[n][1]+1], dtype=object)\n",
    "    lside_trees = np.array([n_trees_dict[i] for i in lside_temp], dtype=object)\n",
    "    rside_trees = np.array([n_trees_dict[i] for i in rside_temp], dtype=object)\n",
    "    multiplied = lside_trees*rside_trees\n",
    "    multiplied[lside_temp==rside_temp] = 0\n",
    "    triangularized = ((lside_trees**2 - lside_trees)//2)+lside_trees\n",
    "    triangularized[lside_temp!=rside_temp] = 0\n",
    "    combined = np.cumsum(multiplied + triangularized)\n",
    "\n",
    "    line_index = np.argmax(combined>tree_index)\n",
    "    if line_index == 0:\n",
    "        index_within = tree_index\n",
    "    else:\n",
    "        index_within = tree_index - combined[line_index-1]\n",
    "    l_children = lside_temp[line_index]\n",
    "    r_children = rside_temp[line_index]\n",
    "    return l_children, r_children, index_within\n",
    "\n",
    "\n",
    "    \n",
    "def select_descendants(l_children, r_children, index_within, n_trees_dict):\n",
    "    \"\"\"\n",
    "    Technically not just selecting the square with this update...\n",
    "    \"\"\"\n",
    "    if l_children != r_children:\n",
    "        l_trees = n_trees_dict[l_children]\n",
    "        r_trees = n_trees_dict[r_children]\n",
    "        lside = (index_within)%l_trees\n",
    "        rside = ((index_within)//l_trees)\n",
    "    else:\n",
    "        l_trees = n_trees_dict[l_children]\n",
    "        lside, rside = triu_indices_AJH(index_within, l_trees)\n",
    "    return lside, rside\n",
    "\n",
    "\n",
    "\n",
    "def build_recursive_full(my_tree, node, lside_arr, rside_arr, n_trees_dict, pointer_dict):\n",
    "    if node.children == []:\n",
    "        return my_tree\n",
    "    for child_node in node.children:\n",
    "        if child_node.name != (np.nan, np.nan, 0):\n",
    "            l_children, r_children, n_within = child_node.name\n",
    "            \n",
    "            l_index, r_index = select_descendants(l_children, r_children, n_within, n_trees_dict)\n",
    "            \n",
    "            l_l_children, l_r_children, l_n_within = select_index(pointer_dict,\\\n",
    "                                            lside_arr, rside_arr, n_trees_dict, l_index, l_children)\n",
    "    \n",
    "            r_l_children, r_r_children, r_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, r_index, r_children)\n",
    "\n",
    "            l_split = child_node.add_child(name=(l_l_children, l_r_children, l_n_within)) \n",
    "            r_split = child_node.add_child(name=(r_l_children, r_r_children, r_n_within))     \n",
    "            my_tree = build_recursive_full(my_tree, child_node,\\\n",
    "                                           lside_arr, rside_arr, n_trees_dict, pointer_dict)\n",
    "    return my_tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1024\n",
    "l_side, r_side, n_trees_dict, pointer_dict = build_dicts(n)\n",
    "testy = []\n",
    "for i in range(100):\n",
    "    tree = build_tree_full(l_side, r_side, n_trees_dict, pointer_dict, n)\n",
    "    tree.name = ''\n",
    "    for node in tree.get_descendants():\n",
    "        node.name = ''\n",
    "    assert len(tree.get_leaves()) == n, len(tree.get_leaves())\n",
    "    testy.append(tree.write('newick', format=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Power_divergenceResult(statistic=0.0, pvalue=1.0)\n"
     ]
    }
   ],
   "source": [
    "counter_dict = Counter(testy)\n",
    "print(len(counter_dict.values()))\n",
    "print(stats.chisquare(list(counter_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for newick in counter_dict.keys():\n",
    "#     print(counter_dict[newick])\n",
    "#     Phylo.draw(Phylo.read(StringIO(newick), 'newick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(counter_dict.keys()):\n",
    "    with open('../{}_uniform_{}.newick'.format(1024, i), 'w') as outfile:\n",
    "        outfile.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28361\n",
      "1 32109\n",
      "2 62705\n",
      "3 38912\n",
      "4 35060\n",
      "5 62744\n",
      "6 50774\n",
      "7 48558\n",
      "8 61041\n",
      "9 45919\n",
      "10 83993\n",
      "11 43588\n",
      "12 61239\n",
      "13 54588\n",
      "14 55030\n",
      "15 75780\n",
      "16 43250\n",
      "17 40924\n",
      "18 38883\n",
      "19 48855\n",
      "20 49310\n",
      "21 32554\n",
      "22 43282\n",
      "23 42163\n",
      "24 53475\n",
      "25 64032\n",
      "26 34027\n",
      "27 70842\n",
      "28 40242\n",
      "29 29935\n",
      "30 38861\n",
      "31 33838\n",
      "32 51150\n",
      "33 54348\n",
      "34 35313\n",
      "35 42390\n",
      "36 33516\n",
      "37 50291\n",
      "38 39481\n",
      "39 38677\n",
      "40 74360\n",
      "41 60125\n",
      "42 29082\n",
      "43 32980\n",
      "44 30677\n",
      "45 30160\n",
      "46 72086\n",
      "47 44777\n",
      "48 47154\n",
      "49 37047\n",
      "50 48873\n",
      "51 53409\n",
      "52 37091\n",
      "53 62023\n",
      "54 48827\n",
      "55 56599\n",
      "56 32901\n",
      "57 42422\n",
      "58 60885\n",
      "59 54891\n",
      "60 42778\n",
      "61 31310\n",
      "62 41848\n",
      "63 41418\n",
      "64 49518\n",
      "65 39095\n",
      "66 53074\n",
      "67 39950\n",
      "68 39758\n",
      "69 24010\n",
      "70 53475\n",
      "71 52159\n",
      "72 32548\n",
      "73 46378\n",
      "74 19329\n",
      "75 33712\n",
      "76 38676\n",
      "77 84011\n",
      "78 54280\n",
      "79 61661\n",
      "80 49100\n",
      "81 71058\n",
      "82 48653\n",
      "83 45860\n",
      "84 33919\n",
      "85 47420\n",
      "86 57381\n",
      "87 51545\n",
      "88 66269\n",
      "89 61712\n",
      "90 28044\n",
      "91 39604\n",
      "92 52776\n",
      "93 26321\n",
      "94 54013\n",
      "95 57108\n",
      "96 35658\n",
      "97 40901\n",
      "98 39991\n",
      "99 65163\n"
     ]
    }
   ],
   "source": [
    "def colless_I(tree, normalized=False):\n",
    "    \"\"\"\n",
    "    Should really figure out a recursive solution to this problem.\n",
    "    \n",
    "    Seems like only using the prior value and the value from one side could ~halve the run time\n",
    "    \n",
    "    Another normalization scheme is the expected under BD model, let\n",
    "    first_part = ((2*n_leaves) / (n_leaves-1) * (n_leaves-2))\n",
    "    \n",
    "    if n_leaves is even:\n",
    "    first_part * np.sum(1./np.arange(2,n_leaves/2))\n",
    "    if odd:\n",
    "    first_part * ((1/n_leaves) + np.sum(1./np.arange(2,(n_leaves-1)/2)))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    node_diff = []\n",
    "    for node in tree.traverse():\n",
    "        try:\n",
    "            a, b = node.get_children()\n",
    "        except ValueError:\n",
    "            continue\n",
    "        node_diff.append(np.abs(len(a.get_leaves())-len(b.get_leaves())))\n",
    "    index_val = np.sum(node_diff)\n",
    "    if normalized:\n",
    "        n_leaves = len(tree.get_leaves())\n",
    "        return index_val/(((n_leaves-1)*(n_leaves-2))/2.)\n",
    "    else:\n",
    "        return index_val\n",
    "    \n",
    "for i, tree in enumerate(testy):\n",
    "    print(i, colless_I(ete3.Tree(tree, format=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X2QZFd53/Hvo1ljXkbWIN6ykbQIYgWMKTPAgABt2OXFLqQorFMlgYAQCStsYgMBYgokKgkOhkSQBFAKl2ALARLBLLLAlkIIoAC7ZmwjsyuGV1m2ImRpkZB4kQbGCMOOnvxxb6OeO+fcOadv37798vtUqXbmzu3u26vZ+/Q5zznPY+6OiIhIqmO6vgAREZksChwiIpJFgUNERLIocIiISBYFDhERyaLAISIiWSYmcJjZ88zsBjO70cwu6Pp6RERmlU3CPg4zmwP+Gvh14AjwJeBF7v7NTi9MRGQGTcqI46nAje5+k7v/FNgP7On4mkREZtK2ri8g0QnArX3fHwFO7T/BzPYCewEe9KAHPfmxj33s6K5ORFpzww03BI/fc889m46tr69vOjY3N5f8WouLi+kXNoUOHz78PXd/2FbnTUrgsMCxDXNs7r4P2AewtLTkhw4dGsV1iciAdu/eveU5KysrrK2tBW/+oSARMj8/n3xNs37fMLO/TTlvUgLHEeCkvu9PBG7r6FpEJFM1SKysrAAbP+H3gkT/jX5tbQ1IDxIhd99998CPlbBJCRxfAk4xs0cB3wbOAV7c7SWJzLaUEQOEgwQUQaH3s5719XVWV1eTr6E6EskZXcjgJiJwuPtRM3sl8GlgDni/u3+j48sSmWipN35g0w2+NxIIjQ6qN+/qKKJnfX3954/pfR8Sy1Hs3Llz07EDBw4Ez5XhmojAAeDunwQ+2fV1iEyilKmi3vHV1dVNN+tY0rn/xt8TOlZ9nZwktILB+JmYwCEiaVKDRKom+YUe3fyniwKHyAQbNEgsLi6ysrKyaQoKNk8Nzc3NRYNHylSVTB8FDpEO5SaY+8XyDOvr6ywvL284t5oPCK1g6gkdCyWsQzkGmQ0KHCIjMuiSVAjfuAGOO+64Dd/Pz8+zurq6aYQQmiqKBS1NK8lWFDhERmD37t2srKwkTyH1CyWbe3KWrlYpQMigFDhERmRxcXHTzTo0CqmOOObn56MBpzolBeFkdpOltzm02W42KHCIDFnoJh0bbaROIcVGB6llO5aXl4O5kFTVKTGZbQocIkOUOiWVa2FhYdOxnE14/T+D+iW2oSChkYT0U+AQSZT66T42JbWysrLlc9SV54ip/iy1bEdsR7aChGxFgUMkQWgkESvKFwsQoV3aocdXRwu9YJKyPyIWYDTVJMOkwCESEEpapyS364TyFNUpqF5wSC3+Fxo17Nq1K+m1RQalwCFSMao8RS9B3X/z7+UeQsdCQj9TkJC2KXDITKtbAdV/Aw7lKHI28EF8z0Xo5l89FhpFiHRFgUNmVs7I4sCBA0nTUouLiywvL9cms/ultjXVKELGiQKHzLQmK6B6QaK6CS9nf8TRo0eTzxUZFwocMjNiCe+q0OgiNgU1jJLjIpNGgUOm0rB7UoSmoBQ0ZFYpcMjUieUuUhLeUJ/g7lfXpyJ2vsg0UOCQqZQaJEIjkNCx1E14dTWgUhscNS1IqJ3f0jYFDpl4KbmL2KqonNVKTZouxYT2dkC4OVOIdoRLFxQ4ZGLE9lxAWu4ip5lRSKxPxjCrzsZKqIfKp4NGF9INBQ4ZS02T27HcRb9YJdnU3tm5N/nQ8+nGL5NIgUPGTs7GvNQcRUhdg6TQdFNd7qP6vCLTTIFDOte0oGBqniInRxGqWnvw4MGkxyvvINNOgUM6lVv2I/YcW4kFg2qRwX6pZUOqNP0k006BQzqXunQ2pC4gVM3NzSVv4Eudbhp2BV2RSaDAISM16NLZuk15O3fu3HQslqDuNzc3l5WPCI1AVHxQZpECh4xM02mpnBxHyqqsQUqgV4V6gWuqSqadAoe0IqfPxbBfq65vd2pnvRCVDBEpKHDI0OV20EvJZ6ysrLC6urrp5t1Lbm/Vt7t3bmqOIxQkVAJdpKDAIa3I6XOxtra2IScRCwYhc3NzwRxH6HpyTEruom43fT9Nn8kwKXDIyMTqRYVGBzk3+km+yYekJPYhHGBFRkGBQ0ZqUm7yIU2KHIb2jMRGVjm1rkKjrUn+O5bJoMAhM2NUBQ1Td46nTrNBfBSiICFdGHngMLOTgMuBfwDcC+xz94vN7Hjgo8DJwM3AC9z9LjMz4GLgDODHwHnuft2or1viUluyDvt16rRRyXbXrl2bjoVu6LF8QtOy7iLjoosRx1Hgd939OjM7FjhsZtcA5wGfdfeLzOwC4ALgDcDpwCnlf6cCl5R/yhjIXUGV87z9YktsY6utYlLLiIRGDU1v8goSMi1GHjjc/Xbg9vLrH5nZ9cAJwB5gd3naZcABisCxB7jc3R34opktmNn28nlkDDTdm5GySzyllWvPMJoedbkKSSMTGXed5jjM7GTgicC1wCN6wcDdbzezh5ennQDc2vewI+WxDYHDzPYCewF27NjR6nXL8IRGLDmjl9i5OVNIw5YTOKvXmTN1JtKVzgKHmc0DHwNe4+4/LFIZ4VMDx3zTAfd9wD6ApaWlTT+X8RXa8zGOBi26CPn5FJFx1kngMLNfoAgaH3b3j5eH7+hNQZnZduDO8vgR4KS+h58I3Da6q5VhGlUiPeW1c8SmzyC8D6WaS8kJGsWsrMj46mJVlQGXAte7+zv6fnQ1cC5wUfnnVX3HX2lm+ymS4qvKb0ymUSXSQ3LKr0O4cm7q0tnQPg4IT6ulbvYTGSddjDhOA14KfM3Mev/C3kgRMK4ws/OBW4Czy599kmIp7o0Uy3FfNtrLlUHEen6nJtJzN9tVq97G6lqlFjTUxjqRuC5WVS0TzlsAPCdwvgOvaPWiZKhipUVgc0Dp3firx1KnhXJWW4XElvEqSIjEaee4tCK1zWto+qbpVFbs8QoG3WlSpys2nahcUHcUOGSkdPOeTG3c+JvW6ZLuKHCIyAapGzJDRRtzpC420IeN8aPAITKj6np5VDdkxlaKNRkhqG/I5FLgEJkBKaMIuG8ksVVjrZicsi4yuRQ4RKZMSoHIugUI1TxFrPz7wYMHNx3LKQGjfMbkUuAQmWCpVYRzhEYWoTL1oeT28vKyyq3MAAUOkQ417SoIm3uMVG/ci4uLLC8vDzz9FDI/P9942bSS3pNLgUNkRFJGB7n9RWBzXazV1dVN00ih3IP2u8igFDhEGqhbmdQvdXQQkjs6CJVV0WolGSYFDpFEqfmEWJfB6o1/fn7+53mBqlBOIPS8R48erb1mkTYocIgkSK3s2wsmoQRxaIQRGkWERgyx0UbqiCdEoxAZlAKHSKJQw6mU2lvDEJv+Ci2JFWmbAodIQGrDqZxEcmpyPDQySS0HD+GKv00qCItUKXCIVDRtOJVayiOkrrxHqlB+RNNSMkwKHCIBgzacqivlkbq/IiRWyiOWiBdpkwKHZOmyZ/i4CY1Mcv8uUvqV5z5vaMSysLCQ/HiNTmQrChySrK2e4ZMi1L0wlDDPkdovPaeURyjHETpPBQllUAockiV1Cmfa1LXDTdV053h1JFJX/yklGa6RhQxKgUNmWiyRnbKCqjcCSx01xJohhXIc1aCQk+MIVbJVGREZJgUOmVlNp95Co5BYcryneqOvjixiNapGOTpoUngxRqOb6aLAITMtZVNfndAn+djj2+h4N4zquv1CdbFCdbZktilwyMwY1YqwptNCOcEgNv3VhHqBy1YUOGQmjMOKsJS6UrEqurFgsGvXrk3HUosmhh4LCgiyNQUOmRlNV4Q1WVWVU0pkbm4ueWNfaApKFXOlbQocMpVSp6VCq6J6N/n+TXN1eyZS8wGhKaCm5UVEuqDAIRNv0L7bdXsz1tfXkz71x3pshB7bRnJcpAsKHDIxcooHhqalUvdc9GpI9YvlGELTT02T0yLjToFDJkJdcjsUJJaXlzfVZ6p226u7wYc23KVutotNP2l0IdNCgUOiuixoGHvtlN3bKysrSVNNc3NzWaOD0LlagSSzSIFDgka5fDU1R1E31VT9lF/dgV23sU1E8ihwSNQoChqmBqhQ7wrI618Reo3QngfQtJJIHQUO6Vxq2Y9YyYvQXojUG39qgyYI5y5Crx0rSKhgJNOis8BhZnPAIeDb7n6mmT0K2A8cD1wHvNTdf2pmvwhcDjwZ+D7wQne/uaPLloba6OWd8johdd36tDJKJK7LEcergeuBXyq/fxvwTnffb2bvAc4HLin/vMvdf9nMzinPe2EXFyzNtJU3Se1zEata2yTX4e4DP1ZkUnUSOMzsROCfAm8F/p2ZGfBs4MXlKZcBv0cROPaUXwNcCbzbzMz1L3YiNcmb5OzjCL1uaKqp6cgi1JJVU1Iy7boacbwLeD1wbPn9Q4C73b1XZOcIcEL59QnArQDuftTMVsvzv9f/hGa2F9gLsGPHjlYvftrkNDNqQ6zsR79YKY/QKCJWWqSuT0aV2qqKxI08cJjZmcCd7n7YzHb3DgdO9YSf3XfAfR+wD2BpaUmjkUSjmj6CcDBKbck6Pz+fdY2pfTJyNuulPn7btvA/q1DQ0uhEJlEXI47TgOeb2RnA/SlyHO8CFsxsWznqOBG4rTz/CHAScMTMtgHHAT8Y/WVPr6bNjKpyg1GXm+hi1xjadQ6bb/6hVVUi027kgcPdLwQuBChHHK9z95eY2R8BZ1GsrDoXuKp8yNXl939R/vxzym+Mv2EHo1xNE+axgFA9nlqaBDS6kOkxTvs43gDsN7O3AF8GLi2PXwp8yMxupBhpnNPR9UlEqORH06mvnCCT2gwplAtZXl7edKPPSZgrGMgs6jRwuPsB4ED59U3AUwPn/AQ4e6QXJslScxQ9qYnwXomQntzVT7HudlWxZHkbe0tEpsU4jThkQqUUHuxXDRSxaaHUYBGaLtJNXqQ9ChwSFZqCgs3TSNWbdGwUkrMktlqkEOKjgy6ni0LvU0FLpp0ChwSFbv5Nl8NC+pLWUQWDnGm21AKLItNOgUOi2vjkPKpP46pVJdIeBY4Z02VzpqZSRwehgBALBnNzc8m1qkIJ91hZdpFppsAxQ0bZnKnuGlKkrLSC+HRR6k0+tQQJKHch0qPAMWNG0ZwpJhS46qaL+vUCROoUUihvcvTo0cCZIpJLgUNaUVerqvrJPaW8h/IOIuNDgUMaS+0Z3vtZaIlvqL94v/n5+cZ1oYrq/Rupeo1IPgUOaSQnb5KaW4klt+fm5rJyEiliU3XKZ4jEJQcOM3s4RTVbANz9llauSMZabFVWakHDlHLnoaZLTQNGKPCsra1x8ODBRs8rMou2DBxm9nzgvwP/ELgTeCRFy9dfbffSpKlhL73NGV3kbACsqltOG9pRHpK69Db1+UTkPikjjt8Hngb8X3d/opk9C3hRu5clTQ1j6W3K6CIWCFLbvKb2Aq9bVdVkCkvVbUXypQSOn7n7983sGDM7xt0/b2Zva/3KpLGm/b1TA08o4V23Izu0nyKltHlsdLBz585Nx5SjEGlPSuC428zmgT8FPmxmdwJaED9FYqXOQ4EnVvU2tG8itiN70GW12ochMh5SAsce4CfAa4GXULRufXObFyX5Bs1n5PTTOHDgAAsLCxuCxDD2V4TKoovI+EoJHI9092+WX18GP2/5eqCla5JMTfMZsZVOoSmo1dXVoSeUlWcQmSwpgeMKM/sQ8HaK5bhvB5aAp7d5YZKnaT4jpjq6qOqNNlJrSInI5EsJHKcCbwP+HDgW+DBwWpsXJe3JTWSHRhdbBYW6n6e2dBWR8ZW0qgq4B3gAxYjjW+5+b6tXJUMRSmSvra1tWtUUWpXUm5bql1OJNmZSVjvl5H1EZk1K4PgScBXwFOAhwHvN7Cx3P6vVK5NGYknv0H6HJpv16h7fpUHLt4MKKopsJSVwnO/uh8qvvwPsMbOXtnhNMiRNb+jjFhBygkE1iZ8bCLSjXCRuy8DRCxqVWlUq8NORunLl0yS14m6sPAk0S9CHRmZa/SVSSKlV9c+Ad6BaVZ0bhw5+bcgpy14VKojY02TEISJxKVNVb0G1qsZGTiXaLuXmGLYKEouLiywvL29K7McCQnWqKXfqSaMLkTjVqpLGQiOGunaw1Wml6nmxIBESCwiaahJpz6C1qn7W7mUJDL8s+jCkBonQjXt+fp61tbVNGwlDS4RzquAqIIiMVkrg+ArwYzbWqhpuGzbZZBzyGYMGidzlrKm1qroOmiJSSAkczyo3/N3LfbWqvtrqVc2gJr0vmrxOTCj3EEpE5zZYCtGIQWSyRAOHmf028DvAP6oEimOBP2v7wqZVaoOjXLFy51u9Tk7vjNRRRN15qoQrMvnqRhx/CPwf4L8AF/Qd/5G7/6DVq5pSddNPKb0vejf+UIBI3d8QSkTHVPMOOY2UYsZtU6GI5IsGDndfBVbR0tuhii2nbVJXCuKl0VM0LTkS20chItMpJcchLRtGXakmFhYWNh0L5S5iU1CafhKZLQocY6JpQEjZfR3LZ1Sr4PZLyWuEprs0JSUyvToJHGa2ALwPeDzgwG8BNwAfBU4GbgZe4O53mZkBFwNnUCwLPs/dr+vgssdCTnI9NC0WGl3EchepyfDl5eXg6EhEplNXI46LgU+5+1lmdj/ggcAbgc+6+0VmdgFFQv4NwOnAKeV/pwKXlH+OvWFv4Mvd27G8vLwhUMT2V4Q21oW6/cXkJMdFZPKNPHCY2S8BzwTOA3D3nwI/NbM9wO7ytMsoepq/AdgDXO7uDnzRzBbMbLu73z7iS8/S1ga+0Cii93pV6+vrmwJAaHSRc+NPTYRv2xb+1dLOb5HJ18WI49HAd4EPmNkTgMPAq4FH9IKBu99elnEHOAG4te/xR8pjGwKHme0F9gLs2LGj1TeQqukGvpwRS2owabL6KrbE9+BBVdkXmSVdBI5twJOAV7n7tWZ2MRv3iVRZ4JhvOuC+D9gHsLS0tOnnbet6WipVNccR2/md0yY2tWItaHQhMg26CBxHgCPufm35/ZUUgeOO3hSUmW2n6P3RO/+kvsefCNw2sqtNMIybfGrJkZQd4r3H56ygiuU+Uhw9enTTsXEs9S4iwzHywOHu3zGzW83sMe5+A/Ac4Jvlf+cCF5V/XlU+5GrglWa2nyIpvtp1fqNJXanQjT+15Ehsv0dOhdocoYR56goqLccVmV5drap6FUWJ9vsBNwEvA44BrjCz84FbgLPLcz9JsRT3RorluC8b/eXep8noInbjh3A+pLoqqnde6LHLy8sbEuFtbNabn59XhVoRwYrFStNlaWnJDx061Ph56vp7h6aQUjbbhfTOqz5+dXV1087tWE+K2PNWhaaVREQAzOywuy9tdZ52jkfUjSxS6kr1PvFXcwqhT/yhT/K5n+w1NSQio6LAUSNnz0RqMyOtKpIu5CxWaFK0Ur/fs0GBYwCpn+61skiGpcmNP9brvY0ujTIbFDhapOkjGUTqqrvcJdfV47Hl1trdL1tR4BAZkUH338QWWSwuLnLw4MHa6sZ1tFBCBqXAITJkqRWM61beVVfEhZp61U01VUcTChIyTAocIgF1N/86oXxC73iobW91/03osSmv10/ViqVtChwylZq0vc2t31UVqucVo3yCTCIFDulc097m1U/doY2SsZFAjtSVRVoUIdNOgUNGKrXFbXXXfEzdKKAaUEJTOLGbfGpJepFZpMAhWVJHB9VELsRHAimjgLpyK6F5/tB5OTd+BQmROAUOSZZak6tuc1lK4jZWbiU2VZUaTERkOBQ4JCqlfHzovN65qZqsVoL4hjcRaYcChwTFijzW9RPpqVuSGurnEbrxVxPRdSXdQ4EntUhkbOpNU1UicQocEpU6uqjK7dsRuvGHlqTW9TJJec5Y21wRyaPAIVmafhIP3fxDN/7QTR7SqxCHhEYxyoWI5FPgkNqGVcN+zlgiPWWz3dzcXPKNPrTnQhvrRIZDgWPGNWmFm/ucsSmllBxHrpyprpDQVFfoOqexg6bIVhQ4ZkyTlVJNnzP18blCN/lt2zb+are1m1xkFilwzJDc0UVoBVXoHAj3ikhdpjvskiGxvEdO8T+tqhKJU+CYYikjgbrlqKHHx3IUoZ3ioWOpye2mN3mVDBFpjwLHlMoZXSwvL29axQSbRxGxMuCwOZkdy1Gk5h6a3uQVJETao8AxxUKji+oU0srKCuvr68HpotBmvdR8QM4KJt3ku9F0sUCIVq7NBgWOGRKafspdTaWbfDeGfZOv2/8SKyYp0qPAMWN04x8vg/Yhh/wFAzmq56v1rPRT4BAZstzGVIP2IY8dbxJgRFIocIgkSh0dhJpQxaaFqosIckvKp4jVDtPoUwalwCEzLRYMUir+1h1LrZ+lG7pMIgUOmUpNcgeQPi20vr6e3A9k165dm44pSMgkUuCYErHNfrMgtY95apCItanNaRgV6peuICHTQoFjCrRRqLBrOQnmak6hN00U2rm+VSK5J7XHxzT9nYukUuCYEqmlRLo26BTSVn03Qj9L2c2uDWsi+RQ4pBV1BQ5TppBycgchChIi7ekkcJjZa4F/BTjwNeBlwHZgP3A8cB3wUnf/qZn9InA58GTg+8AL3f3mLq5bwlJyDDGh+lfDaOeqICHSnpEHDjM7Afi3wOPc/R4zuwI4BzgDeKe77zez9wDnA5eUf97l7r9sZucAbwNeOOzrmpTkchvd+nJeK/TaoWmlUO6gFySquYdQoAitQArlLEAb20RGraupqm3AA8zsZ8ADgduBZwMvLn9+GfB7FIFjT/k1wJXAu83MfIit1yYludzWdea0eYXwjbqadF5bW0sqqw7h1UpagSQyvkYeONz922b234BbgHuAzwCHgbvdvVcQ5whwQvn1CcCt5WOPmtkq8BDge/3Pa2Z7gb0AO3bsyL6uSUkut9Gtr/e81dcJCa0sajq11LRNrIiMVhdTVQ+mGEU8Crgb+CPg9MCpvRGF1fzsvgPu+4B9AEtLS1PRCHrY02d1vcBTmiHFEtmp5TUgby+EiIynLqaqngt8y92/C2BmHweeASyY2bZy1HEicFt5/hHgJOCImW0DjgN+MPrLHq1hTEuFem+k9OjonQsbRx6Li4vBUhwacYjMli4Cxy3A08zsgRRTVc8BDgGfB86iWFl1LnBVef7V5fd/Uf78c8PMb4yznOmz0M2/mmdYX18PnpfTg7w64pifnw+W58hJWGsFlMhk6SLHca2ZXUmx5PYo8GWKKab/Dew3s7eUxy4tH3Ip8CEzu5FipHHOqK95nIRu/P0/6xcaCYSS1rERQ3VlUyzAKJEtMls6WVXl7m8C3lQ5fBPw1MC5PwHOHsV1jbtQBz+or8NUlbqqqfd6kk8tWWXaaef4hIndzOt2avfTDShNbjOmHrVklVmgwDElNDrYaNAbP9x38w8VTkwRqowLsHPnzk3H9P9NJpECh4ylJtM9sU/9TT7xx4JB6Pk0qpNpp8AhrWh644etu+31pO4NyfnEH7p+jQ5ECgoc0ljqRsG6m3+/WI/smNQEc86NP2VDZO71aCQi00KBQxoJbVTM3bQ4qk/ybUx/hWhDo0w7BQ7JEiuDMuyb/7CXtDbNe8Q2OoZoZCHTToFDopr02ci58cc2JFZXNTVJbsdu/KG8ByifIVJHgUOSu/X1vt+q1lVdjmPQulZzc3O6yYuMCQWOGZdbTHF5eZmFhYUNx2JlTEKrnWLLWqu050FkfClwjIkuOxCmllWHIiBUp3xyRhFHjx7d+iRJlloxIES5GBmUAscYGNcOhKnBJHSjGrf3Mq6GscM9hVZ6yTApcIyJSelAqOmijdrY6BgKBqEbfyjhHwskGl3IMClwiASkBIRYX/acqbtq6XrYvMoM8m784/qhQ6aHAseM6TKX0rXcaaH+v5e60vX9n/pzV421MYLTqFDapsAxQ8Y1l5JqVNNCsHlqKPZ3Fss9hKikukwLBY4ZM465lNRpodXV1U3LeWMbA2NLgas39djy4FCg0Cd5kYICh7QiZ1ooJ08QOh7a86ElqSLtUeCQqEFHI7k7x1NHArFgopGAyGgpcIxYbB9EG3mH1ER4tWRI71hsJJDSGS8UDHrHq9QMSWSyKHCM0CiT06mvdeDAgWAwiwWYau4gpzMeNAsITQonggKUyLAocIxYqLxHWwnq1ER4zlRPG53xUnajh0Y7kL/8VUSaU+CYEqPan5EaJJokxyHeDjY1UIQ21ikXIjIcChwtGtXNvK0psEHrKMVaxNa1jk1pkpQzLaYgIdIeBY6WjPJmHurCF7vpxxLhVbENc9VjEB4dhD7xx2jprMhkUeAYkpSWqrm5jFCDJBi88uyBAwdYWFiIjhBCQj9LGR3oE7/I9FLgGII2Rhd1q51CyfVYkNmqM19uUb5QldZYPkJEppMCxwBSRxcpN/OU4z1ra2vBqSYIt3jd6pye0NJV0PJVEQlT4KhRlw+o3oRDLVVXV1c5ePDghmNzc3PBG3Wsn3a/+fn56M1fU0MiMioKHBGxqaKYakvV2PRPbGPcqG78TSrMgkYcIqLAUSt2M6/efHOmgNq68eZsoqsKVZcF5S5EJEyBYwBdTgvFAkSsqGCqnHNFZLYpcIyx1PzK4uJi8ugiRA2GRCRHa4HDzN4PnAnc6e6PL48dD3wUOBm4GXiBu99lZgZcDJwB/Bg4z92vKx9zLvDvy6d9i7tf1tY1j0LTPhWhm3zo3Pn5+eSpJuUtRCRHmyOODwLvBi7vO3YB8Fl3v8jMLii/fwNwOnBK+d+pwCXAqWWgeROwBDhw2Myudve7WrzugaTmGCBciiO1T0XOMtuctqYiIqlaCxzu/qdmdnLl8B5gd/n1ZcABisCxB7jc3R34opktmNn28txr3P0HAGZ2DfA84CNtXXeK1CmkqrrltLG9FKlCQSI04ij+ikVEBjfqHMcj3P12AHe/3cweXh4/Abi177wj5bHY8ZGoG0WE8gzDLJfeG4FUmyZV94X0hHZ0i4i0YVyS4xY45jXHNz+B2V5gL8COHTsaX1BuGZGDBw+ybdt9f5293hEpRQJTE9mx6rCgPIWIjM6oA8cdZra9HG1sB+4sjx8BTurs6CGTAAAHoElEQVQ770TgtvL47srxA6Endvd9wD6ApaWl7PmYUHmQ0CgCwvs4qlNNc3Nzwd3goSml2KqmUD5CjYtEpGujDhxXA+cCF5V/XtV3/JVmtp8iOb5aBpdPA//ZzB5cnvcbwIXDvqjcXeIpwSRkq/0W1eMKEiIyjtpcjvsRitHCQ83sCMXqqIuAK8zsfOAW4Ozy9E9SLMW9kWI57ssA3P0HZvb7wJfK897cS5QPW0rF2Z6Utqaxm37TPhXazS0iXbNpXGWztLTkhw4davw8dc2Q+uX0w57Gv28RmQ5mdtjdl7Y8bxpvZGb2XeBvMx/2UOB7LVxOl6btPU3b+4Hpe0/T9n5gtt7TI939YVs9eCoDxyDM7FBKpJ0k0/aepu39wPS9p2l7P6D3FHLMMC9GRESmnwKHiIhkUeC4z76uL6AF0/aepu39wPS9p2l7P6D3tIlyHCIikkUjDhERyaLAISIiWRQ4ADN7npndYGY3ln1CJo6Zvd/M7jSzr/cdO97MrjGzvyn/fHDdc4wTMzvJzD5vZteb2TfM7NXl8Yl8T2Z2fzP7SzP7Svl+/lN5/FFmdm35fj5qZvfr+lpzmdmcmX3ZzD5Rfj+x78nMbjazr5nZipkdKo9N5O9cT9mm4koz+6vy39PTm76nmQ8cZjYH/AFFM6nHAS8ys8d1e1UD+SBFr5J+vcZZpwCfLb+fFEeB33X3XwGeBryi/P8yqe/p74Fnu/sTgEXgeWb2NOBtwDvL93MXcH6H1zioVwPX930/6e/pWe6+2LfPYVJ/53ouBj7l7o8FnkDx/6rZe3L3mf4PeDrw6b7vLwQu7Pq6BnwvJwNf7/v+BmB7+fV24Iaur7HBe7sK+PVpeE/AA4HrKAp6fg/YVh7f8Ls4Cf9RVKz+LPBs4BMUrRAm9j1RtLR+aOXYxP7OAb8EfItyIdSw3tPMjzjouFlUyzY0zgIevsX5Y6nsJPlE4Fom+D2VUzorFO0ErgH+H3C3ux8tT5nE3713Aa8H7i2/fwiT/Z4c+IyZHS57/MAE/84Bjwa+C3ygnE58n5k9iIbvSYEjo1mUjJ6ZzQMfA17j7j/s+nqacPd1d1+k+JT+VOBXQqeN9qoGZ2ZnAne6++H+w4FTJ+Y9Aae5+5Mopq5fYWbP7PqCGtoGPAm4xN2fCPwdQ5hqU+CIN5GaBneUDbOoNM6aCGb2CxRB48Pu/vHy8ES/JwB3v5uiIdnTgAUz67U3mLTfvdOA55vZzcB+iumqdzHB78ndbyv/vBP4Y4oAP8m/c0eAI+5+bfn9lRSBpNF7UuAoen2cUq4EuR9wDkVjqWnQa5wFGxtnjT0zM+BS4Hp3f0ffjybyPZnZw8xsofz6AcBzKZKUnwfOKk+bmPcD4O4XuvuJ7n4yxb+bz7n7S5jQ92RmDzKzY3tfUzSO+zoT+jsH4O7fAW41s8eUh54DfJOG70k7xwEzO4Pik9Ic8H53f2vHl5Stv3EWcAdF46w/Aa4AdlA2zvKWGmENm5ntBL4AfI375s/fSJHnmLj3ZGa/BlxG8Tt2DHCFu7/ZzB5N8Wn9eODLwL9w97/v7koHY2a7gde5+5mT+p7K6/7j8tttwB+6+1vN7CFM4O9cj5ktAu8D7gfcRNEo7xgavCcFDhERyaKpKhERyaLAISIiWRQ4REQkiwKHiIhkUeAQEZEsChwyE8zs5P7KwSN6zQNmtrTFOa1cl5ntNrNn9H3/QTM7q+4xIqkUOET6lNWSp8Fu4BlbnSQyCAUOmSXbzOwyM/tq2Z/ggfDzHgz/0cyWgbPN7OVm9qWyd8bH+s77oJn9DzP7czO7qf8TvJm9vuzj8BUzu6jvNc8u+3D8tZn9k7qLK4sg/tfytb9qZv+6PL67HL30eip8uNxZj5mdUR5bLq/tE2VRyH8DvLbsK9F73WeGrl0klwKHzJLHAPvc/deAHwK/0/ezn7j7TnffD3zc3Z/iRe+M69nYT2I7sBM4E7gIwMxOB34TOLV8zNv7zt/m7k8FXkOxm7/O+cCquz8FeArwcjN7VPmzJ5bP8TiKiqenmdn9gfcCp7v7TuBhAO5+M/Aeip4Yi+7+hdi1iwxCgUNmya3u/mfl1/+T4iba89G+rx9vZl8ws68BLwF+te9nf+Lu97r7N4FHlMeeC3zA3X8MUCnd0CvOeJiiX0qd3wD+ZVl6/VqKEuWnlD/7S3c/4u73Aivlcz0WuMndv1We85Etnj907SLZtm19isjUqNbX6f/+7/q+/iDwm+7+FTM7jyJf0NNfc8n6/ozV7umdv87W/94MeJW7f3rDwaIOVP/r9p4rVMK8TujaRbJpxCGzZIeZPb38+kXAcuS8Y4Hby7LuL0l43s8Av9WXCzl+wOv7NPDb5etiZv+4rNIa81fAo8ucBsAL+372I4r3ITJ0ChwyS64HzjWzr1JUbr0kct5/oJgquobi5lzL3T9FUab6UDnN9LoBr+99FCWvryuX6L6XmlGKu99Dkaf5VJnYvwNYLX/8v4B/XkmOiwyFquOKTDAzm3f3tXKV1R8Af+Pu7+z6umS6acQhMtleXo5yvgEcRzFKEWmVRhwiIpJFIw4REcmiwCEiIlkUOEREJIsCh4iIZFHgEBGRLP8f5V+aNKHtPjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Phylo.draw(Phylo.read(StringIO(testy[74]), 'newick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recursive_full(my_tree, node, df):\n",
    "    if node.children == []:\n",
    "        return my_tree\n",
    "    for child_node in node.children:\n",
    "        if child_node.name[0] != 0:\n",
    "            child_name, child_n = child_node.name\n",
    "            line = df.loc[child_name]\n",
    "            ###How many options were there\n",
    "            level = df[df[0]==line[0]]\n",
    "            l_n, r_n = select_descendants(child_n,\\\n",
    "                                     df[df[0]==line[1]].iloc[-1][6], df[df[0]==line[2]].iloc[-1][6])\n",
    "            #Now need line and index of these children\n",
    "            l_child_set = df[df[0]==line[1]]\n",
    "            l_line, l_n_within = select_line(l_child_set, l_n)\n",
    "            r_child_set = df[df[0]==line[2]]\n",
    "            r_line, r_n_within = select_line(r_child_set, r_n)\n",
    "            \n",
    "            l_split = child_node.add_child(name=(l_line.name, l_n_within)) \n",
    "            r_split = child_node.add_child(name=(r_line.name, r_n_within))     \n",
    "            my_tree = build_recursive_full(my_tree, child_node, df)\n",
    "\n",
    "    return my_tree\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
