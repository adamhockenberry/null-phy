{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import ete3\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import glob\n",
    "\n",
    "from Bio import Phylo\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '../Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform tree sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First the functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dicts(n):\n",
    "    ###The dictionary that will hold the number of possible trees with a given number of leaves\n",
    "    n_trees_dict = {}\n",
    "    ###It has a few quirks that need to be added manually\n",
    "    n_trees_dict[np.nan] = np.nan\n",
    "    n_trees_dict[1] = 1\n",
    "    \n",
    "    ###Establishing the arrays that hold the number of downstream children on the left and right\n",
    "    ###sides of a bifurcation\n",
    "    l_side = [1]\n",
    "    r_side = [np.nan]\n",
    "    ###A pointer dictionary that tracks where in those arrays trees with a given number of leaves reside\n",
    "    pointer_dict = {}\n",
    "    pointer_dict[1] = (0, 0) #i.e. the first index contains trees related to 1 downstream leaf\n",
    "    \n",
    "    ###Build up the quantities\n",
    "    for tree in range(2, n+1):\n",
    "        starting_index = len(l_side)\n",
    "        range_val = tree//2+1\n",
    "        totals = []\n",
    "        for i in range(1, range_val):\n",
    "            j = tree-i\n",
    "            l_side.append(j)\n",
    "            r_side.append(i)\n",
    "            if i!=j:\n",
    "                totals.append(n_trees_dict[i]*n_trees_dict[j])\n",
    "            else:\n",
    "                totals.append((((n_trees_dict[i]**2)-n_trees_dict[i])//2)+n_trees_dict[i])\n",
    "        ending_index = len(l_side)-1\n",
    "        totals = sum(totals)\n",
    "        n_trees_dict[tree] = totals\n",
    "        pointer_dict[tree] = (starting_index, ending_index)\n",
    "    return l_side, r_side, n_trees_dict, pointer_dict \n",
    "\n",
    "\n",
    "def build_tree_full(lside_arr, rside_arr, n_trees_dict, pointer_dict, n_leaves):\n",
    "    '''\n",
    "    Maybe this is where my recursive algorithm could/should lie?\n",
    "    '''\n",
    "    #Start by first looking at the end of the df\n",
    "    n_trees = n_trees_dict[n]\n",
    "    #Establishing the index of the tree that I want to grab\n",
    "    tree_index = random.randint(0, n_trees-1)\n",
    "    #Getting the number of descendants and index within that set\n",
    "    l_children, r_children, n_within = select_index(pointer_dict,\\\n",
    "                                                    lside_arr, rside_arr, n_trees_dict, tree_index, n)\n",
    "\n",
    "    l_index, r_index = select_descendants(l_children, r_children, n_within, n_trees_dict)\n",
    "    \n",
    "    l_l_children, l_r_children, l_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, l_index, l_children)\n",
    "    \n",
    "    r_l_children, r_r_children, r_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, r_index, r_children)\n",
    "\n",
    "    my_tree = ete3.Tree()\n",
    "    l_split = my_tree.add_child(name=(l_l_children, l_r_children, l_n_within)) \n",
    "    r_split = my_tree.add_child(name=(r_l_children, r_r_children, r_n_within)) \n",
    "    my_tree = build_recursive_full(my_tree, my_tree, lside_arr, rside_arr, n_trees_dict, pointer_dict)\n",
    "    return my_tree\n",
    "\n",
    "def select_index(pointer_dict, lside_arr, rside_arr, n_trees_dict, tree_index, n):\n",
    "    \"\"\"\n",
    "    The real problem is that I'm generating these values at each call\n",
    "    but like if I don't, I'll have to store them and for large n (>100)\n",
    "    this gets positively enormous/prohibitive.\n",
    "    \n",
    "    So instead, I generate this on the fly each time around? \n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return np.nan, np.nan, 0\n",
    "    lside_temp = np.array(lside_arr[pointer_dict[n][0]:pointer_dict[n][1]+1], dtype=object)\n",
    "    rside_temp = np.array(rside_arr[pointer_dict[n][0]:pointer_dict[n][1]+1], dtype=object)\n",
    "    lside_trees = np.array([n_trees_dict[i] for i in lside_temp], dtype=object)\n",
    "    rside_trees = np.array([n_trees_dict[i] for i in rside_temp], dtype=object)\n",
    "    multiplied = lside_trees*rside_trees\n",
    "    multiplied[lside_temp==rside_temp] = 0\n",
    "    triangularized = ((lside_trees**2 - lside_trees)//2)+lside_trees\n",
    "    triangularized[lside_temp!=rside_temp] = 0\n",
    "    combined = np.cumsum(multiplied + triangularized)\n",
    "\n",
    "    line_index = np.argmax(combined>tree_index)\n",
    "    if line_index == 0:\n",
    "        index_within = tree_index\n",
    "    else:\n",
    "        index_within = tree_index - combined[line_index-1]\n",
    "    l_children = lside_temp[line_index]\n",
    "    r_children = rside_temp[line_index]\n",
    "    return l_children, r_children, index_within\n",
    "\n",
    "\n",
    "    \n",
    "def select_descendants(l_children, r_children, index_within, n_trees_dict):\n",
    "    \"\"\"\n",
    "    Technically not just selecting the square with this update...\n",
    "    \"\"\"\n",
    "    if l_children != r_children:\n",
    "        l_trees = n_trees_dict[l_children]\n",
    "        r_trees = n_trees_dict[r_children]\n",
    "        lside = (index_within)%l_trees\n",
    "        rside = ((index_within)//l_trees)\n",
    "    else:\n",
    "        l_trees = n_trees_dict[l_children]\n",
    "        lside, rside = triu_indices_AJH(index_within, l_trees)\n",
    "    return lside, rside\n",
    "\n",
    "\n",
    "\n",
    "def build_recursive_full(my_tree, node, lside_arr, rside_arr, n_trees_dict, pointer_dict):\n",
    "    if node.children == []:\n",
    "        return my_tree\n",
    "    for child_node in node.children:\n",
    "        if child_node.name != (np.nan, np.nan, 0):\n",
    "            l_children, r_children, n_within = child_node.name\n",
    "            \n",
    "            l_index, r_index = select_descendants(l_children, r_children, n_within, n_trees_dict)\n",
    "            \n",
    "            l_l_children, l_r_children, l_n_within = select_index(pointer_dict,\\\n",
    "                                            lside_arr, rside_arr, n_trees_dict, l_index, l_children)\n",
    "    \n",
    "            r_l_children, r_r_children, r_n_within = select_index(pointer_dict,\\\n",
    "                                                lside_arr, rside_arr, n_trees_dict, r_index, r_children)\n",
    "\n",
    "            l_split = child_node.add_child(name=(l_l_children, l_r_children, l_n_within)) \n",
    "            r_split = child_node.add_child(name=(r_l_children, r_r_children, r_n_within))     \n",
    "            my_tree = build_recursive_full(my_tree, child_node,\\\n",
    "                                           lside_arr, rside_arr, n_trees_dict, pointer_dict)\n",
    "    return my_tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####This might actually work!\n",
    "def triu_indices_AJH(i, mat_len):\n",
    "    \"\"\"\n",
    "    This function gets the triangular indices from a square matrix (including the diagonal). \n",
    "    It was developed with a bit of guess and check and using some functions/solutions I found \n",
    "    online but it looks robust. Should be tested more extensively but my test against numpy triu_indices()\n",
    "    works well (and this of course skips the matrix building step).\n",
    "    \n",
    "    Critical differences to some fxns found online were making sure it runs on integer math to handle\n",
    "    enormous numbers.\n",
    "    \n",
    "    Relies on isqrt, which should be the python implementation in >3.8 but Newton's method works (slowly)\n",
    "    \n",
    "    Inputs:\n",
    "        i - the linear index of interest\n",
    "        m - the dimensions of one side of the square matrix\n",
    "        \n",
    "    Outputs\n",
    "        row index\n",
    "        column index\n",
    "    \"\"\"\n",
    "    ii = (mat_len*(mat_len+1))//2-1-i\n",
    "    K = (isqrt(8*ii+1)-1)//2\n",
    "    row = mat_len-1-K\n",
    "    return row, i - (mat_len*(mat_len-1)//2) + ((mat_len-row)*((mat_len-row)-1))//2\n",
    "\n",
    "\n",
    "def triu_accuracy_test(max_n_to_test):\n",
    "    \"\"\"\n",
    "    Tests the accuracy of my triangle indices test compared to numpy.\n",
    "    The advantage of mine is not having to actually build the matrix and instead work directly \n",
    "    with the dimensions.\n",
    "    \n",
    "    Will run slowly so am arbitrarily limiting max_n_to_test to 200\n",
    "    \"\"\"\n",
    "    if max_n_to_test > 100:\n",
    "        max_n_to_test = 100\n",
    "        print(\"Setting max variable to test to 100, test takes a long time otherwise.\")\n",
    "    for n in range(1, max_n_to_test+1):\n",
    "        for k in range(((n**2-n)//2)+n):\n",
    "            i, j = triu_indices_AJH(k, n)\n",
    "            assert np.triu_indices(n, k=0)[0][k] == i\n",
    "            assert np.triu_indices(n, k=0)[1][k] == j, print('###',np.triu_indices(n, k=0)[1][k], j)\n",
    "\n",
    "def isqrt(n):\n",
    "    \"\"\"\n",
    "    Integer square root. Need to upgrade to python 3.8 for math.isqrt()\n",
    "    \"\"\"\n",
    "    x = n\n",
    "    y = (x + 1) // 2\n",
    "    while y < x:\n",
    "        x = y\n",
    "        y = (x + n // x) // 2\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now run it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "l_side, r_side, n_trees_dict, pointer_dict = build_dicts(n)\n",
    "tree_list = []\n",
    "for i in range(100):\n",
    "    tree = build_tree_full(l_side, r_side, n_trees_dict, pointer_dict, n)\n",
    "    tree.name = ''\n",
    "    for node in tree.get_descendants():\n",
    "        node.name = ''\n",
    "    assert len(tree.get_leaves()) == n, len(tree.get_leaves())\n",
    "    tree_list.append(tree.write('newick', format=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###This is just a simple test of uniformity to ensure everything is working as planned\n",
    "# counter_dict = Counter(tree_list)\n",
    "# print(len(counter_dict.values()))\n",
    "# print(stats.chisquare(list(counter_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tree in enumerate(tree_list):\n",
    "    with open(out_dir+'{}_uniformTopology_{}.newick'.format(n, i), 'w') as outfile:\n",
    "        outfile.write(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth-death tree sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insert(listy, item):\n",
    "    '''\n",
    "    I preliminarily tested 2 options for inserting and randomizing new items:\n",
    "    \n",
    "    1.\n",
    "    listy = list(range(1000))\n",
    "    random_insert(listy, 'a')\n",
    "    random_insert(listy, 'b')\n",
    "    \n",
    "    2.\n",
    "    listy = list(range(1000))\n",
    "    listy.extend(['a', 'b'])\n",
    "    random.shuffle(listy)\n",
    "    \n",
    "    Obviously the former doesn't randomize the whole list but I found the implementation using random_insert \n",
    "    to be absurdly quicker. As long as the list is grown from an initially randomly shuffled I think that\n",
    "    this would produce a fully random output. So this function is currently used below.\n",
    "    \n",
    "    '''\n",
    "    listy.insert(random.randrange(len(listy)+1), item)\n",
    "\n",
    "def get_bd_topology(n_extant_taxa):\n",
    "    '''\n",
    "    Docs\n",
    "    \n",
    "    Restrictions beta>=mu\n",
    "    \n",
    "    \n",
    "    \n",
    "    Algorithm notes:\n",
    "    1. Code is definitely worse than O(n). But don't think that it's quadratic.\n",
    "    2. Should perhaps test random insertion of the two new children to avoid the \n",
    "        re-shuffling step... but are two random insertions worse than one random re-shuffling?\n",
    "    '''\n",
    "    my_tree = ete3.Tree() # Instantiate an empty tree\n",
    "    #Add two leaves to start the first bifurcation\n",
    "    A = my_tree.add_child(name=\"\", dist=0.) \n",
    "    B = my_tree.add_child(name=\"\", dist=0.) \n",
    "    #And put those leaves in a list of who to draw from\n",
    "    all_leaves = [A, B]\n",
    "    random.shuffle(all_leaves)\n",
    "    for i in range(n_extant_taxa-2):\n",
    "        #Choose a random leaf, add two children to it\n",
    "        choice = all_leaves[-1]\n",
    "        new_A = choice.add_child(name=\"\", dist=0.)\n",
    "        new_B = choice.add_child(name=\"\", dist=0.)\n",
    "        #Remove the leaf and randomly add its children to our running list of extant\n",
    "        all_leaves = all_leaves[:-1]\n",
    "        random_insert(all_leaves, new_A)\n",
    "        random_insert(all_leaves, new_B)\n",
    "    return my_tree\n",
    "\n",
    "def rotate_tree(my_tree):\n",
    "    a, b = my_tree.get_children()\n",
    "    if len(a.get_descendants()) < len(b.get_descendants()):\n",
    "        my_tree.swap_children()\n",
    "    for node in my_tree.get_descendants():\n",
    "        if not node.is_leaf():\n",
    "            a, b = node.get_children()\n",
    "            if len(a.get_descendants()) < len(b.get_descendants()):\n",
    "                node.swap_children()\n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32\n",
    "tree_list = []\n",
    "for i in range(100):\n",
    "    tree = get_bd_topology(n)\n",
    "    assert len(tree.get_leaves()) == n, len(tree.get_leaves())\n",
    "    tree = rotate_tree(tree)\n",
    "    assert len(tree.get_leaves()) == n, len(tree.get_leaves())\n",
    "    tree_list.append(tree.write('newick', format=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tree in enumerate(tree_list):\n",
    "    with open(out_dir+'{}_bdTopology_{}.newick'.format(n, i), 'w') as outfile:\n",
    "        outfile.write(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "test_trees = []\n",
    "for tree_file in glob.glob(out_dir+'*32_bdTopology*'):\n",
    "    test_trees.append(ete3.Tree(tree_file, format=100))\n",
    "test_tree_strings = [tree.write('newick', format=100) for tree in test_trees]\n",
    "print(len(test_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dict = Counter(test_tree_strings)\n",
    "unique_trees_str = list(counter_dict.keys())\n",
    "if len(unique_trees_str) < 10:\n",
    "    for newick in unique_trees_str:\n",
    "        print(counter_dict[newick])\n",
    "        Phylo.draw(Phylo.read(StringIO(newick), 'newick'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure tree is bifurcating with no polytomies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree in test_trees:\n",
    "    assert set([len(tree.children)]+\\\n",
    "               [len(i.children) for i in tree.get_descendants() if i.is_leaf()==False]) == {2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
